{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Start Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Sentiment Classification with Tuning\") \\\n",
    "    .getOrCreate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. Load training data\n",
    "train_df = spark.read.json(\"../Data/train_data.json\")\n",
    "test1_df = spark.read.json(\"../Data/test1_data.json\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. Prepare function to label\n",
    "def prepare(df):\n",
    "    df = df.select(\"reviewText\", \"overall\")\n",
    "    df = df.withColumn(\"label\", when(col(\"overall\") < 3, 0)\n",
    "                                 .when(col(\"overall\") == 3, 1)\n",
    "                                 .otherwise(2))\n",
    "    return df.dropna(subset=[\"reviewText\", \"label\"])\n",
    "\n",
    "train_data = prepare(train_df)\n",
    "test1_data = prepare(test1_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. Define stages\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=20)\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5. Hyperparameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [1000, 5000, 10000]) \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6. Evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 7. CrossValidator with test1_data as evaluation set\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3,\n",
    "                    parallelism=2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 8. Fit model on train_data\n",
    "cv_model = cv.fit(train_data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 9. Evaluate on test1_data\n",
    "predictions = cv_model.transform(test1_data)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"âœ… Test1 Accuracy: {accuracy:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 10. Save best model\n",
    "model_path = \"../Data/Best_SentimentModel\"\n",
    "if os.path.exists(model_path):\n",
    "    import shutil\n",
    "    shutil.rmtree(model_path)\n",
    "cv_model.bestModel.write().overwrite().save(model_path)\n",
    "\n",
    "print(\"ðŸŽ¯ Best model saved successfully!\")\n",
    "\n",
    "# 11. Stop Spark\n",
    "spark.stop()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
